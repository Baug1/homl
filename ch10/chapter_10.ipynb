{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdf1cde3-16f1-42a7-9b89-70b587cb59b4",
   "metadata": {},
   "source": [
    "## The Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb31cf88-7dfc-4485-a12e-e3715452ec70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for [2, 0.5] - True\n",
      "Prediction for [3, 1] - False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y = (iris.target == 0) # Iris setosa\n",
    "\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "X_new = [[2, 0.5], [3, 1]]\n",
    "y_pred = per_clf.predict(X_new) # Predicts true/false for these two flowers\n",
    "\n",
    "for i in range(2):\n",
    "    print(f\"Prediction for {X_new[i]} - {y_pred[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258f4836-fd0e-4cd2-b74a-cf7c78c7f29e",
   "metadata": {},
   "source": [
    "Scikit-learn's ```Perceptron``` class is equivalent to using ```SDGClassifier``` with the follwing hyperparameters:\n",
    "```loss=\"perceptron\", learning_rate=\"constant\", eta0=1, penalty=None``` (no regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d9a76a-eeeb-4a8b-be58-4ecb886311d9",
   "metadata": {},
   "source": [
    "#### Activation functions\n",
    "![](images/activation_functions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c71bfe-f49f-46fc-a0cd-a456d19bad49",
   "metadata": {},
   "source": [
    "## Regression MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ff2fa95-0238-4677-ae13-95553f751b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes=[50, 50, 50], random_state=42)\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_reg)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "rmse = root_mean_squared_error(y_valid, y_pred)\n",
    "\n",
    "print(f\"RMSE: {root_mean_squared_error(y_valid, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a58eb0f-8509-4ffe-920a-41e792317ffd",
   "metadata": {},
   "source": [
    "#### Typical regression MLP architecture\n",
    "\n",
    "| Hyperparameter | Typical value |\n",
    "|-|-|\n",
    "| # hidden layers | Depends on the problem, but typically 1 to 5 |\n",
    "| # neurons per hidden layer | Depends on the problem, but typically 10 to 100 |\n",
    "| # output neurons | 1 per prediction dimension |\n",
    "| Hidden activation | ReLU |\n",
    "| Output activation | None, or ReLU/softplus (if positive outputs) or sigmoid/tanh (if bounded outputs) |\n",
    "| Loss function | MSE, or Huber if outliers |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5ed2fc-3fda-4fe3-b3b2-2fa23bbac391",
   "metadata": {},
   "source": [
    "## Classification MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "687f5f07-b1f5-41b3-bfd9-cb625deef702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.1, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.1, random_state=42)\n",
    "\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=[5], random_state=42, max_iter=10000)\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_clf)\n",
    "pipeline.fit(X_train, y_train)\n",
    "accuracy = pipeline.score(X_valid, y_valid)\n",
    "\n",
    "print(f\"accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d0f02-836a-4605-9cc0-1f4fea3d40cf",
   "metadata": {},
   "source": [
    "#### Typical classification MLP architecture\n",
    "\n",
    "| Hyperparameter | Binary classification | Multilabel binary classification | Multiclass classification | \n",
    "|-|-|-|-|\n",
    "| # hidden layers | 1-5 | 1-5 | 1-5 |\n",
    "| # output neurons | 1 | 1 per binary label | 1 per class |\n",
    "| Output layer activation | Sigmoid | Sigmoid | Softmax | \n",
    "| Loss function | X-entropy | X-entropy | X-entropy |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117b7c94-1b81-49aa-bd14-51f157e651d3",
   "metadata": {},
   "source": [
    "## Implementing MLP's with Keras\n",
    "\n",
    "#### Using Keras to load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb25a3a-150f-4534-9b5a-026c8cf9e065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3f93dab-7199-4a7c-93f3-a4025dc91d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169c2a4d-53ff-407f-bb27-ae43a10972d9",
   "metadata": {},
   "source": [
    "Let's scale the pixel intensities down to the 0-1 range and convert them to floats, by dividing by 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80c69ff5-f2f0-4dd1-b0ec-3534ad44edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f025eb-97b2-4003-9d34-6c8e5dd3ad3a",
   "metadata": {},
   "source": [
    "Corresponding class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fd7ca28-7182-4d96-9b04-3ead2590b25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f23797-68d2-4a5a-ba66-f848f3f2f643",
   "metadata": {},
   "source": [
    "#### Samples from Fashion MNIST\n",
    "\n",
    "![](images/fashion_mnist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
